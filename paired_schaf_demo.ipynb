{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36c1f1b7-2424-42f4-b897-3ae2bb8a2ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import torch\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import argparse\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from typing import Dict, List, Tuple, Set, Union, Optional\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, TensorDataset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import wandb\n",
    "import scanpy as sc\n",
    "from tqdm import tqdm\n",
    "import sklearn.model_selection\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "from numba import njit, prange\n",
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.spatial import cKDTree\n",
    "import tangram as tg\n",
    "import imageio.v3 as iio\n",
    "import cv2\n",
    "import scgpt\n",
    "import timm\n",
    "from einops import rearrange\n",
    "from torch import einsum\n",
    "import torch.nn.utils as U\n",
    "\n",
    "from schaf_method import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '7'  # replace as needed \n",
    "\n",
    "# Configure system settings\n",
    "Image.MAX_IMAGE_PIXELS = 933120000  # Allow loading large images\n",
    "DEVICE = torch.device(\"cuda:7\")  # replace as needed \n",
    "device = DEVICE\n",
    "NUM_WORKERS = 6 if torch.cuda.is_available() else 2\n",
    "PIN_MEMORY = torch.cuda.is_available()\n",
    "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = pow(2,40).__str__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "569e4a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:1500 training genes are saved in `uns``training_genes` of both single cell and spatial Anndatas.\n",
      "INFO:root:1500 overlapped genes are saved in `uns``overlap_genes` of both single cell and spatial Anndatas.\n",
      "INFO:root:uniform based density prior is calculated and saved in `obs``uniform_density` of the spatial Anndata.\n",
      "INFO:root:rna count based density prior is calculated and saved in `obs``rna_count_based_density` of the spatial Anndata.\n",
      "INFO:root:Allocate tensors for mapping.\n",
      "INFO:root:Begin training with 1500 genes and rna_count_based density_prior in cells mode...\n",
      "INFO:root:Printing scores every 100 epochs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.916, KL reg: 0.001\n",
      "Score: 0.918, KL reg: 0.000\n",
      "Score: 0.920, KL reg: 0.000\n",
      "Score: 0.921, KL reg: 0.000\n",
      "Score: 0.921, KL reg: 0.000\n",
      "Score: 0.921, KL reg: 0.000\n",
      "Score: 0.921, KL reg: 0.000\n",
      "Score: 0.921, KL reg: 0.000\n",
      "Score: 0.921, KL reg: 0.000\n",
      "Score: 0.921, KL reg: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saving results..\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create example single-cell data\n",
    "n_cells = 1000\n",
    "n_genes = 2000\n",
    "expression_matrix = np.random.negative_binomial(5, 0.3, size=(n_cells, n_genes))\n",
    "adata_sc = sc.AnnData(X=expression_matrix)\n",
    "adata_sc.obs.index = [f\"cell_{i}\" for i in range(n_cells)]\n",
    "adata_sc.var.index = [f\"gene_{i}\" for i in range(n_genes)]\n",
    "adata_sc.obs['cluster'] = np.random.choice([0, 1, 2, 3], n_cells)\n",
    "\n",
    "\n",
    "# Create example spatial transcriptomics data\n",
    "n_cells = 500\n",
    "x_coords = np.random.uniform(0, 1000, n_cells)\n",
    "y_coords = np.random.uniform(0, 1000, n_cells)\n",
    "spatial_genes = adata_sc.var.index[:1500]  # Use subset of genes\n",
    "spatial_expression = np.random.negative_binomial(3, 0.4, size=(n_cells, len(spatial_genes)))\n",
    "adata_st = sc.AnnData(X=spatial_expression)\n",
    "adata_st.obs.index = [f\"spatial_cell_{i}\" for i in range(n_cells)]\n",
    "adata_st.var.index = spatial_genes\n",
    "adata_st.obsm['spatial'] = np.column_stack([x_coords, y_coords])\n",
    "adata_st.obs['fold'] = np.random.choice([0, 1, 2, 3], n_cells)\n",
    "adata_st.obs['x'] = x_coords\n",
    "adata_st.obs['y'] = y_coords\n",
    "\n",
    "# Create a dummy H&E image\n",
    "he_image = np.random.randint(0, 255, size=(1000, 1000, 3), dtype=np.uint8)\n",
    "\n",
    "# he_image, adata_st, adata_sc\n",
    "# do tangram \n",
    "st_for_tang = adata_st.copy()\n",
    "sc_for_tang = adata_sc.copy()\n",
    "\n",
    "sc.pp.filter_cells(sc_for_tang, min_genes=8)\n",
    "sc.pp.filter_genes(sc_for_tang, min_cells=1)\n",
    "sc.pp.normalize_total(sc_for_tang)\n",
    "sc.pp.log1p(sc_for_tang)\n",
    "\n",
    "# Process spatial data\n",
    "sc.pp.filter_cells(st_for_tang, min_genes=8)\n",
    "sc.pp.filter_genes(st_for_tang, min_cells=1)\n",
    "sc.pp.normalize_total(st_for_tang)\n",
    "sc.pp.log1p(st_for_tang)\n",
    "\n",
    "# Find common genes\n",
    "common_genes = np.intersect1d(sc_for_tang.var.index, st_for_tang.var.index)\n",
    "sc_for_tang = sc_for_tang[:, common_genes]\n",
    "st_for_tang = st_for_tang[:, common_genes]\n",
    "tg.pp_adatas(sc_for_tang, st_for_tang)\n",
    "ad_map = tg.map_cells_to_space(\n",
    "    adata_sc=sc_for_tang,\n",
    "    adata_sp=st_for_tang,\n",
    "    device=DEVICE\n",
    ")\n",
    "projected_adata = tg.project_genes(ad_map, adata_sc)\n",
    "\n",
    "projected_adata.X = projected_adata.X / 10.\n",
    "he_image = he_image / 255.\n",
    "sc.pp.log1p(adata_st)\n",
    "\n",
    "# he_image, adata_st, projected_adata\n",
    "# samples correspond to zones in he_image\n",
    "HOLD_OUT_FOLD = 1 \n",
    "train_st = adata_st[adata_st.obs['fold']!=HOLD_OUT_FOLD] \n",
    "test_st = adata_st[adata_st.obs['fold']==HOLD_OUT_FOLD]  \n",
    "train_projected = projected_adata[projected_adata.obs['fold']!=HOLD_OUT_FOLD]  \n",
    "test_projected = projected_adata[projected_adata.obs['fold']==HOLD_OUT_FOLD]\n",
    "st_mean = train_st.X.mean(axis=0) \n",
    "st_std = train_st.X.std(axis=0)  \n",
    "proj_mean = train_projected.X.mean(axis=0) \n",
    "proj_std =  train_projected.X.std(axis=0) \n",
    "train_st.X = (train_st.X - st_mean) / st_std\n",
    "train_projected.X = (train_projected.X - proj_mean) / proj_std\n",
    "\n",
    "train_stage1_dl = DataLoader(\n",
    "    ImageDataset(\n",
    "    he_image=he_image,\n",
    "        adata=train_st,\n",
    "        tile_radius=10,\n",
    "        indices=list(range(train_st.shape[0])),\n",
    "    ),batch_size=64,\n",
    "    shuffle=1,\n",
    "    num_workers=1,\n",
    "    pin_memory=1\n",
    ")\n",
    "\n",
    "train_stage2_dl = DataLoader(\n",
    "    ImageDataset(\n",
    "        he_image=he_image,\n",
    "        adata=train_projected,\n",
    "        tile_radius=10,\n",
    "        indices=list(range(train_projected.shape[0])),\n",
    "    ),batch_size=64,\n",
    "    shuffle=1,\n",
    "    num_workers=1,\n",
    "    pin_memory=1\n",
    ")\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    ImageDataset(\n",
    "        he_image=he_image,\n",
    "        adata=test_st,\n",
    "        tile_radius=10,\n",
    "        indices=list(range(test_st.shape[0])),\n",
    "   ),batch_size=64,\n",
    "    shuffle=1,\n",
    "    num_workers=1,\n",
    "    pin_memory=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cd55565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:11<00:00,  1.86s/it]\n",
      "100%|██████████| 6/6 [00:10<00:00,  1.81s/it]\n"
     ]
    }
   ],
   "source": [
    "# train \n",
    "\n",
    "stage1_model = MerNet(\n",
    "    num_genes=train_st.shape[1],\n",
    "    model_name='xj_transformer',\n",
    "    pretrained=True,\n",
    "    num_hidden_layers=1,\n",
    "    pretrain_hist=True,\n",
    "    pretrain_st='NONE'\n",
    ").to(device)\n",
    "criterion = nn.MSELoss()\n",
    "lr = 1e-4\n",
    "stage1_optimizer = optim.Adam(stage1_model.parameters(), lr=lr)\n",
    "\n",
    "NUM_EPOCHS = 1\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Training phase\n",
    "    stage1_model.train()\n",
    "    num_batches = 0\n",
    "    \n",
    "    for images, transcripts in tqdm(train_stage1_dl,):\n",
    "        images = images.to(device)\n",
    "        transcripts = transcripts.to(device)\n",
    "        \n",
    "        stage1_optimizer.zero_grad()\n",
    "        outputs = stage1_model(images)\n",
    "        loss = criterion(outputs, transcripts)\n",
    "        loss.backward()\n",
    "        stage1_optimizer.step()\n",
    "        \n",
    "\n",
    "stage2_model = MerNet(\n",
    "    num_genes=train_projected.shape[1],\n",
    "    model_name='xj_transformer',\n",
    "    pretrained=True,\n",
    "    num_hidden_layers=3,\n",
    "    pretrain_hist=True,\n",
    "    pretrain_st='NONE'\n",
    ")\n",
    "stage2_model.part_one = stage1_model.part_one\n",
    "# load the weights in \n",
    "\n",
    "stage2_model = stage2_model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "lr = 1e-4\n",
    "stage2_optimizer = optim.Adam(stage2_model.parameters(), lr=lr)\n",
    "\n",
    "NUM_EPOCHS = 1\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Training phase\n",
    "    stage2_model.train()\n",
    "    num_batches = 0\n",
    "    \n",
    "    for images, transcripts in tqdm(train_stage2_dl,):\n",
    "        images = images.to(device)\n",
    "        transcripts = transcripts.to(device)\n",
    "        \n",
    "        stage2_optimizer.zero_grad()\n",
    "        outputs = stage2_model(images)\n",
    "        loss = criterion(outputs, transcripts)\n",
    "        loss.backward()\n",
    "        stage2_optimizer.step()\n",
    "        \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc98a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# infer \n",
    "inferred_transcripts = []\n",
    "with torch.no_grad():\n",
    "    for images, transcripts in test_dl:\n",
    "        images = images.to(device)\n",
    "        transcripts = transcripts.to(device)\n",
    "        \n",
    "        outputs = stage2_model(images)\n",
    "        inferred_transcripts.extend(outputs.cpu().detach().numpy())\n",
    "inferred_adata = sc.AnnData(X=np.array(inferred_transcripts))\n",
    "inferred_adata.obs = test_st.obs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_schaf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
